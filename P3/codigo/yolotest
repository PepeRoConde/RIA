import cv2
from ultralytics import YOLO
import numpy as np

# Cargar modelo YOLO pose
model = YOLO('yolov8m-pose.pt')

# Abrir webcam
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

def detectar_posicion_brazos(keypoints):
    """
    Detecta posición de brazos usando YOLO keypoints
    Keypoints YOLO:
    5,6: hombros
    7,8: codos
    9,10: muñecas
    """
    
    if len(keypoints) < 11:
        return "SIN BRAZOS"
    
    keypoints = np.array(keypoints)
    
    # Extraer puntos clave
    hombro_izq = keypoints[5]   # índice 5
    hombro_der = keypoints[6]   # índice 6
    codo_izq = keypoints[7]     # índice 7
    codo_der = keypoints[8]     # índice 8
    muñeca_izq = keypoints[9]   # índice 9
    muñeca_der = keypoints[10]  # índice 10
    
    # Validar que los puntos fueron detectados (x,y > 0)
    brazos_detectados = {
        'izq': muñeca_izq[0] > 0 and muñeca_izq[1] > 0,
        'der': muñeca_der[0] > 0 and muñeca_der[1] > 0
    }
    
    # Si no se detectan brazos
    if not brazos_detectados['izq'] and not brazos_detectados['der']:
        return "SIN BRAZOS"
    
    # Altura de hombros
    altura_hombro_izq = hombro_izq[1]
    altura_hombro_der = hombro_der[1]
    
    # Altura de muñecas
    altura_muñeca_izq = muñeca_izq[1]
    altura_muñeca_der = muñeca_der[1]
    
    # Posición horizontal de muñecas
    x_muñeca_izq = muñeca_izq[0]
    x_muñeca_der = muñeca_der[0]
    x_hombro_izq = hombro_izq[0]
    x_hombro_der = hombro_der[0]
    
    # Distancia entre muñecas
    distancia_muñecas = abs(x_muñeca_der - x_muñeca_izq)
    
    # Umbrales más estrictos
    brazo_izq_arriba = altura_muñeca_izq < altura_hombro_izq - 100
    brazo_der_arriba = altura_muñeca_der < altura_hombro_der - 100
    
    brazo_izq_abajo = altura_muñeca_izq > altura_hombro_izq + 150
    brazo_der_abajo = altura_muñeca_der > altura_hombro_der + 150
    
    # 1. BRAZOS EN CRUZ
    if (brazo_izq_arriba and brazo_der_arriba and 
        distancia_muñecas > 200 and
        abs(altura_muñeca_izq - altura_muñeca_der) < 80):
        return "BRAZOS EN CRUZ"
    
    # 4. BRAZOS ABAJO
    if brazos_detectados['izq'] and brazos_detectados['der'] and brazo_izq_abajo and brazo_der_abajo:
        return "BRAZOS ABAJO"
    
    # 2. BRAZO DERECHO (solo si el izquierdo NO está arriba)
    if brazos_detectados['der'] and brazo_der_arriba and not brazo_izq_arriba:
        return "BRAZO DERECHO"
    
    # 3. BRAZO IZQUIERDO (solo si el derecho NO está arriba)
    if brazos_detectados['izq'] and brazo_izq_arriba and not brazo_der_arriba:
        return "BRAZO IZQUIERDO"
    
    # 5. BRAZOS RELAJADOS
    return "BRAZOS RELAJADOS"

print("Presiona 'q' para salir")

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Voltear para selfie
    frame = cv2.flip(frame, 1)
    
    # Detectar con YOLO
    results = model(frame, verbose=False)
    
    # Dibujar detecciones
    annotated_frame = results[0].plot()
    
    # Procesar keypoints
    for result in results:
        if result.keypoints is not None:
            keypoints = result.keypoints.xy.cpu().numpy()
            
            for person_idx, person_keypoints in enumerate(keypoints):
                posicion = detectar_posicion_brazos(person_keypoints)
                
                # Colores para cada posición
                colores = {
                    "BRAZO DERECHO": (255, 0, 0),
                    "BRAZO IZQUIERDO": (0, 165, 255),
                    "BRAZOS EN CRUZ": (0, 255, 0),
                    "BRAZOS ABAJO": (0, 0, 255),
                    "BRAZOS RELAJADOS": (255, 255, 0),
                    "SIN BRAZOS": (128, 128, 128)
                }
                
                color = colores.get(posicion, (255, 255, 255))
                
                # Mostrar en pantalla
                cv2.rectangle(annotated_frame, (10, 10), (550, 70), color, -1)
                cv2.putText(annotated_frame, f"Posicion: {posicion}", 
                            (20, 55), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 0), 3)
    
    cv2.imshow('YOLO - Detección de Brazos', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()